{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab,Twitter,Okt,Kkma\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    \"정말 맛있습니다. 추천합니다.\",\n",
    "    \"기대했던 것보단 별로였네요.\",\n",
    "    \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n",
    "    \"완전 최고입니다! 재방문 의사 있습니다.\",\n",
    "    \"음식도 서비스도 다 만족스러웠습니다.\",\n",
    "    \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n",
    "    \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n",
    "    \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n",
    "    \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n",
    "    \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"       \n",
    "]\n",
    "\n",
    "test_words = [\"음식\", \"맛\", \"서비스\", \"위생\", \"가격\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenized(data):\n",
    "    tokenized = []\n",
    "    for sent in tqdm(data):\n",
    "        tokens = tokenizer.morphs(sent, stem=True)\n",
    "        tokenized.append(tokens)\n",
    "\n",
    "    return tokenized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 179243.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = make_tokenized(train_data)\n",
    "\n",
    "word_count = defaultdict(int)\n",
    "\n",
    "for tokens in tqdm(train_tokenized):\n",
    "    for token in tokens:\n",
    "        word_count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 14), ('도', 7), ('이다', 4), ('좋다', 4), ('별로', 3), ('다', 3), ('이', 3), ('너무', 3), ('음식', 3), ('서비스', 3), ('하다', 2), ('방문', 2), ('위생', 2), ('좀', 2), ('더', 2), ('에', 2), ('조금', 2), ('정말', 1), ('맛있다', 1), ('추천', 1), ('기대하다', 1), ('것', 1), ('보단', 1), ('가격', 1), ('비싸다', 1), ('다시', 1), ('가다', 1), ('싶다', 1), ('생각', 1), ('안', 1), ('드네', 1), ('요', 1), ('완전', 1), ('최고', 1), ('!', 1), ('재', 1), ('의사', 1), ('있다', 1), ('만족스럽다', 1), ('상태', 1), ('가', 1), ('개선', 1), ('되다', 1), ('기르다', 1), ('바라다', 1), ('맛', 1), ('직원', 1), ('분들', 1), ('친절하다', 1), ('기념일', 1), ('분위기', 1), ('전반', 1), ('적', 1), ('으로', 1), ('짜다', 1), ('저', 1), ('는', 1), ('신경', 1), ('써다', 1), ('불쾌하다', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(list(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 788897.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['정말', '맛있다', '.', '추천', '하다', '.'], ['기대하다', '것', '보단', '별로', '이다', '.'], ['다', '좋다', '가격', '이', '너무', '비싸다', '다시', '가다', '싶다', '생각', '이', '안', '드네', '요', '.'], ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.'], ['음식', '도', '서비스', '도', '다', '만족스럽다', '.'], ['위생', '상태', '가', '좀', '별로', '이다', '.', '좀', '더', '개선', '되다', '기르다', '바라다', '.'], ['맛', '도', '좋다', '직원', '분들', '서비스', '도', '너무', '친절하다', '.'], ['기념일', '에', '방문', '하다', '음식', '도', '분위기', '도', '서비스', '도', '다', '좋다', '.'], ['전반', '적', '으로', '음식', '이', '너무', '짜다', '.', '저', '는', '별로', '이다', '.'], ['위생', '에', '조금', '더', '신경', '써다', '좋다', '.', '조금', '불쾌하다', '.']]\n",
      "{'.': 0, '도': 1, '이다': 2, '좋다': 3, '별로': 4, '다': 5, '이': 6, '너무': 7, '음식': 8, '서비스': 9, '하다': 10, '방문': 11, '위생': 12, '좀': 13, '더': 14, '에': 15, '조금': 16, '정말': 17, '맛있다': 18, '추천': 19, '기대하다': 20, '것': 21, '보단': 22, '가격': 23, '비싸다': 24, '다시': 25, '가다': 26, '싶다': 27, '생각': 28, '안': 29, '드네': 30, '요': 31, '완전': 32, '최고': 33, '!': 34, '재': 35, '의사': 36, '있다': 37, '만족스럽다': 38, '상태': 39, '가': 40, '개선': 41, '되다': 42, '기르다': 43, '바라다': 44, '맛': 45, '직원': 46, '분들': 47, '친절하다': 48, '기념일': 49, '분위기': 50, '전반': 51, '적': 52, '으로': 53, '짜다': 54, '저': 55, '는': 56, '신경': 57, '써다': 58, '불쾌하다': 59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2i = {}\n",
    "for pair in tqdm(word_count):\n",
    "    if pair[0] not in w2i:\n",
    "        w2i[pair[0]] = len(w2i)\n",
    "\n",
    "i2w  ={v:k for k,v in w2i.items()}  \n",
    "print(train_tokenized)\n",
    "print(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 15, 16, 14, 57, 58, 3, 0, 16, 59, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = [w2i[token] for token in tokens]\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = torch.LongTensor([]) # input word\n",
    "        self.y = torch.LongTensor([]) # target word\n",
    "        \n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i-window_size >= 0 and i+window_size < len(token_ids):\n",
    "                    ############################ ANSWER HERE ################################\n",
    "                    # TODO 1: insert tokens for input self.x\n",
    "                    # TODO 2: insert tokens for targets self.y\n",
    "                    #########################################################################        \n",
    "                    tokens_in_window = token_ids[i-window_size:i+window_size+1]\n",
    "                    x_tensor = torch.LongTensor(tokens_in_window[:window_size] + token_ids[-window_size:])\n",
    "                    y_tensor = torch.LongTensor([id])\n",
    "\n",
    "                    self.x = torch.cat((self.x, F.one_hot(x_tensor, num_classes=len(w2i))))\n",
    "                    self.y = torch.cat((self.y, F.one_hot(y_tensor, num_classes=len(w2i))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = torch.Tensor([])\n",
    "        self.y = torch.Tensor([])\n",
    "\n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i-window_size >= 0 and i+window_size < len(token_ids):\n",
    "                    ############################ ANSWER HERE ################################\n",
    "                    # TODO 1: insert tokens for input self.x\n",
    "                    # TODO 2: insert tokens for targets self.y\n",
    "                    #########################################################################        \n",
    "                    tokens_in_window = token_ids[i-window_size:i+window_size+1]\n",
    "                    x_tensor = torch.LongTensor([id])\n",
    "                    y_tensor = torch.LongTensor(tokens_in_window[:window_size] + token_ids[-window_size:])\n",
    "\n",
    "                    self.x = torch.cat((self.x, F.one_hot(x_tensor, num_classes=len(w2i))))\n",
    "                    self.y = torch.cat((self.y, F.one_hot(y_tensor, num_classes=len(w2i))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1605.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3981.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]))]\n",
      "[(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), (tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), (tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_set = CBOWDataset(train_tokenized)\n",
    "skipgram_set = SkipGramDataset(train_tokenized)\n",
    "print(list(skipgram_set)[:3])\n",
    "print(list(cbow_set)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n",
    "        self.linear = nn.Linear(dim, vocab_size)\n",
    "\n",
    "    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "    def forward(self, x):  # x: (B, 2W)\n",
    "        embeddings = self.embedding(x)  # (B, 2W, d_w)\n",
    "        embeddings = torch.sum(embeddings, dim=1)  # (B, d_w)\n",
    "        output = self.linear(embeddings)  # (B, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "  def __init__(self, vocab_size, dim, window_size=2):\n",
    "    super(SkipGram, self).__init__()\n",
    "    self.window_size = window_size\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embedding = nn.Embedding(self.vocab_size, dim, sparse=True)\n",
    "    self.linear = nn.Linear(dim, self.vocab_size * self.window_size * 2)\n",
    "\n",
    "  # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "  def forward(self, x): # x: (B)\n",
    "    embeddings = self.embedding(x)  # (B, d_w)\n",
    "    output = self.linear(embeddings)  # (B, V * W)\n",
    "    output = output.view(-1, self.window_size * 2, self.vocab_size)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(vocab_size=len(w2i), dim=256)\n",
    "skipgram = SkipGram(vocab_size=len(w2i), dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 5\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "cbow_loader = DataLoader(cbow_set, batch_size=batch_size)\n",
    "skipgram_loader = DataLoader(skipgram_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/koowater/Code/goorm K-Digital/Narual Language Processing/Word2Vec.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000014?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m cbow(x)  \u001b[39m# (B, V)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000014?line=13'>14</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000014?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000014?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000014?line=16'>17</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1164\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1165\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2995\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2996\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "cbow.train()\n",
    "cbow = cbow.to(device)\n",
    "optim = torch.optim.SGD(cbow.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs+1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(cbow_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = cbow(x)  # (B, V)\n",
    "    \n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 19, 22,  4]) tensor([[17, 18, 10,  0],\n",
      "        [18,  0, 10,  0],\n",
      "        [20, 21,  2,  0],\n",
      "        [21, 22,  2,  0]])\n",
      "tensor([[-1.4292, -0.5033,  0.3522,  0.0107, -0.2754,  0.3695,  0.0407, -0.4617,\n",
      "         -0.1086,  0.6471,  0.0039,  0.1783,  0.9259,  0.1736,  1.0363,  0.0282,\n",
      "          0.0685,  0.1797,  0.3769, -0.4552, -0.6126, -0.6303, -0.0737, -0.2349,\n",
      "          0.8764, -0.5239, -1.2522,  0.2579, -0.4421, -0.9994, -0.4711,  0.1125,\n",
      "         -0.3440, -0.3643,  0.9844,  0.2379, -0.4586,  0.1930,  0.2406, -0.8169,\n",
      "          0.0051, -0.7984,  0.3381,  0.0923, -0.1215, -0.2333, -0.2954,  0.6058,\n",
      "         -0.1679,  0.1534, -0.4813, -0.0274,  0.1318, -0.2471, -0.4369, -0.3706,\n",
      "          0.4833, -0.5089, -0.5341,  0.7908],\n",
      "        [-0.2617,  0.0820, -0.8226, -0.1968,  0.7589, -0.6089,  0.0048, -0.5277,\n",
      "          0.4508,  0.2631,  0.5016,  0.4225, -0.0973,  0.0471,  0.7230,  0.0104,\n",
      "         -0.9979, -1.0905,  0.4761, -0.3524,  0.7428, -0.6272,  0.3647, -0.4594,\n",
      "          0.3459, -0.1415,  0.0375,  0.5158,  0.8995, -0.0461, -0.0405,  0.4528,\n",
      "          0.9817, -1.5916,  0.8599,  0.3609, -0.7944, -0.1814, -0.1132, -0.0220,\n",
      "          0.7832, -0.8856,  0.4931,  0.2479, -0.1237, -0.6993, -0.8271, -1.2293,\n",
      "          0.6896,  0.3129, -0.3602, -0.3361,  0.1737, -0.1746,  0.6233,  0.5213,\n",
      "         -1.0880, -0.1219,  0.0028,  0.4183],\n",
      "        [-0.5643,  0.7646, -0.2963,  0.5664,  0.4182,  0.3230,  0.2756, -0.9744,\n",
      "          0.9364,  0.4276,  0.5204, -0.3928, -0.9507,  0.0782, -0.4889,  0.6087,\n",
      "          0.5808,  0.3279,  0.3177, -0.3345,  0.7187,  0.4779,  0.8333, -0.0891,\n",
      "          0.6048, -0.1773,  0.9052,  0.0132, -0.4161, -0.0732,  0.3215,  0.6395,\n",
      "         -1.2220,  0.4517,  0.7456,  0.9176, -0.9164, -0.2653, -1.4325, -0.3971,\n",
      "          0.7399,  0.8661, -0.1840,  0.5194, -0.5364, -0.8480,  0.6329, -0.5107,\n",
      "         -1.4673,  0.1179,  0.0222, -0.0621, -0.1834, -1.4954, -0.1165,  0.3219,\n",
      "         -0.1429,  0.2911, -0.5982, -1.1775],\n",
      "        [-0.5695,  1.4215,  0.8990,  0.6698,  0.7003, -1.6092, -0.2943,  0.6372,\n",
      "          0.4027, -0.5303,  0.6548, -0.4355, -0.0899, -0.0294,  0.0678, -0.5078,\n",
      "         -0.2899, -0.3228, -0.4692,  0.0511,  0.4840, -0.1947, -0.5124, -0.5664,\n",
      "          0.7598, -0.4815,  0.8858, -0.5870, -0.4802,  0.7204, -0.5249, -1.2830,\n",
      "         -1.0962,  0.0655,  0.4772, -1.0244, -0.6242, -0.4357,  0.1888,  0.3420,\n",
      "         -0.8061, -0.1851, -0.0885, -0.1843, -0.9666, -0.4202,  0.0462,  0.1677,\n",
      "         -0.1715, -0.4660, -0.6493, -0.7996,  0.0478, -0.4328,  1.0548, -1.1505,\n",
      "         -0.8011, -0.4375,  0.3632,  1.1487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/koowater/Code/goorm K-Digital/Narual Language Processing/Word2Vec.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000016?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000016?line=15'>16</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000016?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000016?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/koowater/Code/goorm%20K-Digital/Narual%20Language%20Processing/Word2Vec.ipynb#ch0000016?line=18'>19</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1164\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1165\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2995\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2996\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "skipgram.train()\n",
    "skipgram = skipgram.to(device)\n",
    "optim = torch.optim.SGD(skipgram.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs+1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(skipgram_loader):\n",
    "        x, y = batch\n",
    "        print(x, y)\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = skipgram(x)  # (B, V)\n",
    "        print(output)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = cbow.embedding(input_id)\n",
    "\n",
    "    print(f\"Word: {word}\")\n",
    "    print(emb.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = skipgram.embedding(input_id)\n",
    "\n",
    "    print(f\"Word: {word}\")\n",
    "    print(max(emb.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word,top_k=5):\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    input_emb = skipgram.embedding(input_id)\n",
    "    score=torch.matmul(input_emb,skipgram.embedding.weight.transpose(1,0)).view(-1)\n",
    "\n",
    "    _,top_k_ids=torch.topk(score,top_k)\n",
    "\n",
    "    return [i2w[word_id.item()] for word_id in top_k_ids][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"가격\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#matplotlib 패키지 한글 깨짐 처리 시작\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "#plt.rc('font', family='AppleGothic') #맥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_componenbts=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_weight = pca.fit_transform(skipgram.embedding.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for word_id,(x_coordinate,y_coordinate) in enumerate(pc_weight):\n",
    "    plt.scatter(x_coordinate,y_coordinate,color=\"blue\")\n",
    "    plt.annotate(i2w[word_id], (x_coordinate, y_coordinate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
