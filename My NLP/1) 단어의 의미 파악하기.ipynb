{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어의 의미 파악하기\n",
    "\n",
    "딥러닝이 사용되기 이전에 어떤 방식으로 단어의 의미를 파악했는지 알아보자.\n",
    "\n",
    "## 시소러스(Thesaurus)\n",
    "\n",
    "> 정의: 단어를 의미에 따라 분류·배열한 일종의 유의어 사전\n",
    "\n",
    "시소러스는 단어 사이의 상하 관계나 포함 관계를 고려하여 정의할 수도 있다. (이 경우엔 그래프로 표현)\n",
    "\n",
    "단점: 시대 변화에 대응이 어렵다. 많은 인력이 필요하다. 단어의 미묘한 차이를 표현할 수 없다.\n",
    "\n",
    "WordNet: 1985년부터 프린스턴 대학교에서 구축하기 시작한 가장 유명한 시소러스\n",
    "\n",
    "## 통계 기반 기법\n",
    "\n",
    "- **말뭉치(corpus)**: 수집된 텍스트 데이터. 추가 정보가 포함되는 경우가 있다(품사, 긍정 부정 여부 등).\n",
    "\n",
    "말뭉치를 전처리하여 쉽게 다룰 수 있도록 코드를 작성해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'you say goodbye and I say hello.'\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어를 효율적으로 조작하기 위해 id를 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    new_id = len(word_to_id)\n",
    "    word_to_id[word] = new_id\n",
    "    id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 5, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치 전처리 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(t):\n",
    "    text = t.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split()\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return  corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 분산 표현\n",
    "\n",
    "우리는 색을 3차원 벡터(RGB)로 표현한다. 데이터로 표현하기도 쉽고 색 끼리의 관련성을 판단하기도 용이하다. \n",
    "\n",
    "이처럼 단어도 벡터 공간 상에 표현할 수 있다. 이를 단어의 **분산표현(distributional representation)** 이라고 한다.\n",
    "\n",
    "### 분포 가설\n",
    "\n",
    "> 단어의 의미는 주변 단어에 의해 형성된다. 단어 그 자체에는 의미가 없다. 단어가 사용된 맥락(context)이 의미를 형성한다.\n",
    "\n",
    "이는 분포 가설(distributional hypothesis)의 핵심이다. \n",
    "\n",
    "- 맥락(context)\n",
    "\n",
    "    특정 단어를 중심에 둔 그 주변 단어를 의미한다.\n",
    "    \n",
    "    - 맥락의 크기 = window size\n",
    "    \n",
    "        ex) window size가 2이면 좌측 두 단어, 우측 두 단어가 맥락에 포함된다.\n",
    "        \n",
    "### 동시발생 행렬\n",
    "\n",
    "> 어떤 단어의 맥락이 되는 다른 단어의 출현 빈도를 행렬로 표현한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 1, 5, 6]),\n",
       " {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6},\n",
       " {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fe5cb_row0_col1, #T_fe5cb_row1_col0, #T_fe5cb_row1_col2, #T_fe5cb_row1_col4, #T_fe5cb_row1_col5, #T_fe5cb_row2_col1, #T_fe5cb_row2_col3, #T_fe5cb_row3_col2, #T_fe5cb_row3_col4, #T_fe5cb_row4_col1, #T_fe5cb_row4_col3, #T_fe5cb_row5_col1, #T_fe5cb_row5_col6, #T_fe5cb_row6_col5 {\n",
       "  background-color: #a0c0ff;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fe5cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fe5cb_level0_col0\" class=\"col_heading level0 col0\" >you</th>\n",
       "      <th id=\"T_fe5cb_level0_col1\" class=\"col_heading level0 col1\" >say</th>\n",
       "      <th id=\"T_fe5cb_level0_col2\" class=\"col_heading level0 col2\" >goodbye</th>\n",
       "      <th id=\"T_fe5cb_level0_col3\" class=\"col_heading level0 col3\" >and</th>\n",
       "      <th id=\"T_fe5cb_level0_col4\" class=\"col_heading level0 col4\" >i</th>\n",
       "      <th id=\"T_fe5cb_level0_col5\" class=\"col_heading level0 col5\" >hello</th>\n",
       "      <th id=\"T_fe5cb_level0_col6\" class=\"col_heading level0 col6\" >.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row0\" class=\"row_heading level0 row0\" >you</th>\n",
       "      <td id=\"T_fe5cb_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_fe5cb_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_fe5cb_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_fe5cb_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_fe5cb_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_fe5cb_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row1\" class=\"row_heading level0 row1\" >say</th>\n",
       "      <td id=\"T_fe5cb_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_fe5cb_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_fe5cb_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_fe5cb_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_fe5cb_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "      <td id=\"T_fe5cb_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_fe5cb_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row2\" class=\"row_heading level0 row2\" >goodbye</th>\n",
       "      <td id=\"T_fe5cb_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_fe5cb_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_fe5cb_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_fe5cb_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_fe5cb_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_fe5cb_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row3\" class=\"row_heading level0 row3\" >and</th>\n",
       "      <td id=\"T_fe5cb_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_fe5cb_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "      <td id=\"T_fe5cb_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_fe5cb_row3_col4\" class=\"data row3 col4\" >1</td>\n",
       "      <td id=\"T_fe5cb_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_fe5cb_row3_col6\" class=\"data row3 col6\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row4\" class=\"row_heading level0 row4\" >i</th>\n",
       "      <td id=\"T_fe5cb_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_fe5cb_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_fe5cb_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_fe5cb_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_fe5cb_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_fe5cb_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row5\" class=\"row_heading level0 row5\" >hello</th>\n",
       "      <td id=\"T_fe5cb_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "      <td id=\"T_fe5cb_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_fe5cb_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_fe5cb_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_fe5cb_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_fe5cb_row5_col6\" class=\"data row5 col6\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe5cb_level0_row6\" class=\"row_heading level0 row6\" >.</th>\n",
       "      <td id=\"T_fe5cb_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_fe5cb_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_fe5cb_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_fe5cb_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_fe5cb_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_fe5cb_row6_col5\" class=\"data row6 col5\" >1</td>\n",
       "      <td id=\"T_fe5cb_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1b2c4f95e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def draw_color_at_nan(x, color):\n",
    "    if x == 1:\n",
    "        color = f'background-color:{color}'\n",
    "        return color\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "index = [id_to_word[i] for i in range(vocab_size)]\n",
    "\n",
    "df = pd.DataFrame(C, index=index, columns=index)\n",
    "df.style.applymap(draw_color_at_nan, color='#a0c0ff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 간 유사도\n",
    "\n",
    "단어 벡터 사이의 유사도를 나타낼 때 **코사인 유사도(cosine similarity)** 를 자주 이용한다.\n",
    "\n",
    "$$\\text{similarity}(\\textbf{x}, \\textbf{y}) = cos(\\theta) = \\frac{\\textbf{x} \\cdot \\textbf{y}}{\\lVert \\textbf{x} \\rVert \\lVert \\textbf{y} \\rVert} = \\frac{x_1y_1+ \\cdots +x_ny_n}{\\sqrt{x_1^2+ \\cdots + x_n^2}\\sqrt{y_1^2+ \\cdots + y_n^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta$는 두 벡터 $\\textbf{x}, \\textbf{y}$ 가 이루는 각도이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = x / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"you\"와 \"i\"의 유사도를 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사 단어의 랭킹을 표시할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    # 1. 검색어를 꺼낸다.\n",
    "    if query not in word_to_id:\n",
    "        print(f'{query}를 찾을 수 없습니다.')\n",
    "        return\n",
    "    \n",
    "    print(f'\\n[query] {query}')\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    # 2. 코사인 유사도 계산\n",
    "    #    모든 word에 대해 유사도를 계산하고 정렬한다.\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "    \n",
    "    # 3. 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    for i in (-1 * similarity).argsort()[:top]: # 내림차순 argsort를 수행하는 간단한 trick\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(f'{id_to_word[i]}: {similarity[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      "say: 1.9999999700000004\n",
      "goodbye: 1.4142135382309597\n",
      "and: 1.4142135382309597\n",
      "i: 1.4142135382309597\n",
      "hello: 1.4142135382309597\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법 개선하기\n",
    "\n",
    "### 상호정보량\n",
    "\n",
    "단어 간의 동시발생 만으로 관계를 유추하는 것은 위험하다. ex) the, car, drive\n",
    "\n",
    "### 점별 상호정보량(Pointwise mutual Information) PMI\n",
    "\n",
    "$$\\text{PMI}(x, y)=log_2\\frac{P(x, y)}{P(x)P(y)}$$\n",
    "\n",
    "- $P(x)$: 단어 $x$가 말뭉치에 등장할 확률\n",
    "- $C(x)$: 단어 $x$의 등장 횟수\n",
    "- $C(x, y)$: 단어 $x$와 $y$가 동시 발생하는 횟수\n",
    "\n",
    "$$\\text{PMI}(x, y)=log_2\\frac{P(x, y)}{P(x)P(y)}=log_2\\frac{\\frac{C(x, y)}{N}}{\\frac{C(x)}{N}\\frac{C(y)}{N}}=log_2\\frac{C(x, y)\\cdot N}{C(x)C(y)}$$\n",
    "\n",
    "$\\text{PMI}$의 문제점은 두 단어의 동시발생 횟수가 0이면 $log_{2}0=-\\infty$가 된다. 이 때문에 양의 상호정보량(Positive PMI)를 사용한다.\n",
    "\n",
    "$$\\text{PPMI}=\\text{max}(0, \\text{PMI}(x, y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0) # 단어 x의 출현 횟수\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j] * S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total // 100 + 1) == 0:\n",
    "                    print(f'{100 * cnt / total:.1f} 완료')\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "W = ppmi(C)\n",
    "print(C)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPMI에도 여전히 문제가 있다.\n",
    "\n",
    "- 말뭉치의 어휘가 증가함에 따라 각 던어 벡터의 차원 수도 증가한다.\n",
    "- 원소가 대부분 0로 이루어져있는 희소행렬일 가능성이 높다. -> 각 원소의 중요도가 낮다.\n",
    "- 노이즈에 약하고 견고하지 못하다.\n",
    "\n",
    "다음과 같은 문제를 해결하기 위해 차원감소가 사용된다.\n",
    "\n",
    "### 차원감소\n",
    "\n",
    "SVD(Singular Value Decomposition, 특잇값분해)를 이용하여 차원을 감소시킬 수 있다. \n",
    "\n",
    "SVD는 임의의 행렬을 세 행렬의 곱으로 분해한다.\n",
    "\n",
    "$$\\text{X}=\\text{USV}^\\text{T}$$\n",
    "\n",
    "SVD가 기억나지 않는다면 선형대수학 자료를 참고하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([0.   , 1.807, 0.   , 0.   , 0.   , 0.   , 0.   ], dtype=float32),\n",
       " array([ 3.409e-01, -1.110e-16, -1.205e-01, -4.163e-16, -9.323e-01,\n",
       "        -1.110e-16, -2.426e-17], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, S, V = np.linalg.svd(W)\n",
    "C[0], W[0], U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "\n",
    "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB 데이터셋\n",
    "\n",
    "더 큰 말뭉치를 사용하여 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "len(id_to_word): 10000\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id[\"car\"]: 3856\n",
      "word_to_id[\"happy\"]: 4428\n",
      "word_to_id[\"lexus\"]: 7426\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print(f'말뭉치 크기: {len(corpus)}')\n",
    "print(f'corpus[:30]: {corpus[:30]}')\n",
    "print(f'len(id_to_word): {len(id_to_word)}\\n')\n",
    "print(f'id_to_word[0]: {id_to_word[0]}')\n",
    "print(f'id_to_word[1]: {id_to_word[1]}')\n",
    "print(f'id_to_word[2]: {id_to_word[2]}\\n')\n",
    "print(f'word_to_id[\"car\"]: {word_to_id[\"car\"]}')\n",
    "print(f'word_to_id[\"happy\"]: {word_to_id[\"happy\"]}')\n",
    "print(f'word_to_id[\"lexus\"]: {word_to_id[\"lexus\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산...\n",
      "PPMI 계산...\n",
      "1.0 완료\n",
      "2.0 완료\n",
      "3.0 완료\n",
      "4.0 완료\n",
      "5.0 완료\n",
      "6.0 완료\n",
      "7.0 완료\n",
      "8.0 완료\n",
      "9.0 완료\n",
      "10.0 완료\n",
      "11.0 완료\n",
      "12.0 완료\n",
      "13.0 완료\n",
      "14.0 완료\n",
      "15.0 완료\n",
      "16.0 완료\n",
      "17.0 완료\n",
      "18.0 완료\n",
      "19.0 완료\n",
      "20.0 완료\n",
      "21.0 완료\n",
      "22.0 완료\n",
      "23.0 완료\n",
      "24.0 완료\n",
      "25.0 완료\n",
      "26.0 완료\n",
      "27.0 완료\n",
      "28.0 완료\n",
      "29.0 완료\n",
      "30.0 완료\n",
      "31.0 완료\n",
      "32.0 완료\n",
      "33.0 완료\n",
      "34.0 완료\n",
      "35.0 완료\n",
      "36.0 완료\n",
      "37.0 완료\n",
      "38.0 완료\n",
      "39.0 완료\n",
      "40.0 완료\n",
      "41.0 완료\n",
      "42.0 완료\n",
      "43.0 완료\n",
      "44.0 완료\n",
      "45.0 완료\n",
      "46.0 완료\n",
      "47.0 완료\n",
      "48.0 완료\n",
      "49.0 완료\n",
      "50.0 완료\n",
      "51.0 완료\n",
      "52.0 완료\n",
      "53.0 완료\n",
      "54.0 완료\n",
      "55.0 완료\n",
      "56.0 완료\n",
      "57.0 완료\n",
      "58.0 완료\n",
      "59.0 완료\n",
      "60.0 완료\n",
      "61.0 완료\n",
      "62.0 완료\n",
      "63.0 완료\n",
      "64.0 완료\n",
      "65.0 완료\n",
      "66.0 완료\n",
      "67.0 완료\n",
      "68.0 완료\n",
      "69.0 완료\n",
      "70.0 완료\n",
      "71.0 완료\n",
      "72.0 완료\n",
      "73.0 완료\n",
      "74.0 완료\n",
      "75.0 완료\n",
      "76.0 완료\n",
      "77.0 완료\n",
      "78.0 완료\n",
      "79.0 완료\n",
      "80.0 완료\n",
      "81.0 완료\n",
      "82.0 완료\n",
      "83.0 완료\n",
      "84.0 완료\n",
      "85.0 완료\n",
      "86.0 완료\n",
      "87.0 완료\n",
      "88.0 완료\n",
      "89.0 완료\n",
      "90.0 완료\n",
      "91.0 완료\n",
      "92.0 완료\n",
      "93.0 완료\n",
      "94.0 완료\n",
      "95.0 완료\n",
      "96.0 완료\n",
      "97.0 완료\n",
      "98.0 완료\n",
      "99.0 완료\n",
      "SVD 계산...\n",
      "\n",
      "[query] you\n",
      "who: 2.6198220252990723\n",
      "into: 2.6063780784606934\n",
      "mr.: 2.519623279571533\n",
      "his: 2.4457719326019287\n",
      "an: 2.42289400100708\n",
      "\n",
      "[query] year\n",
      "who: 4.465244293212891\n",
      "into: 4.442330360412598\n",
      "mr.: 4.294464588165283\n",
      "his: 4.1685919761657715\n",
      "an: 4.129598617553711\n",
      "\n",
      "[query] car\n",
      "who: 3.6143922805786133\n",
      "into: 3.5958445072174072\n",
      "mr.: 3.4761548042297363\n",
      "his: 3.374267101287842\n",
      "an: 3.3427040576934814\n",
      "\n",
      "[query] toyota\n",
      "who: 7.131003379821777\n",
      "into: 7.094409465789795\n",
      "mr.: 6.8582682609558105\n",
      "his: 6.6572489738464355\n",
      "an: 6.594976425170898\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('SVD 계산...')\n",
    "try:\n",
    "    # truncated SVD(특이값이 큰 것들만 계산해서 빠르다!)\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
